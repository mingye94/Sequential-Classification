{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of 6864-hw2b.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU7xWiY6TyWS"
      },
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf 6864-hw2b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AyMA9rK1Rhf"
      },
      "source": [
        "import os\n",
        "os.makedirs(\"6864-hw2b\", exist_ok=True)\n",
        "import sys\n",
        "sys.path.append(\"/content/6864-hw2b\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL1IfnRdPdsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2c11fe33-a425-4d90-828c-411ec6f77470"
      },
      "source": [
        "!pip install sacrebleu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/58/5c6cc352ea6271125325950715cf8b59b77abe5e93cf29f6e60b491a31d9/sacrebleu-1.4.6-py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
            "\u001b[?25hCollecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1MB 197kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/64/03/9abfb3374d67838daf24f1a388528714bec1debb1d13749f0abd7fb07cfb/portalocker-1.6.0-py2.py3-none-any.whl\n",
            "Installing collected packages: mecab-python3, portalocker, sacrebleu\n",
            "Successfully installed mecab-python3-0.996.5 portalocker-1.6.0 sacrebleu-1.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fOArV2r9Piz"
      },
      "source": [
        "# **Part 3: Sequence-to-Sequence Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA9JfWiK9eoL"
      },
      "source": [
        "In this lab, you will explore RNN-based sequence-to-sequence (seq2seq) models to perform machine translation (MT). We will use a Vietnamese-English dataset from IWSLT'15. The task is to translate a Vietnamese sentence into English.\n",
        "\n",
        "The lab is divided into two parts. The first part is to implement a vanilla seq2seq architecture without attention. In the second part you will implement your favorite attention mechanism (doesn't have to come from lecture) and add it to your vanilla seq2seq model. We will provide the training and testing scripts (trust me, the decoding/testing is actually the hardest part :P), so you will mainly just have to focus on implementing the models (I say *mainly* because you still might need to modify the testing script, depending on which attention method you use and how you implement it).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDJjmvZfHV_l"
      },
      "source": [
        "## **Section 1: Data Preprocessing**\n",
        "\n",
        "No need to write any code in this section. But you are encouraged to test with this part to understand the data.\n",
        "\n",
        "First, we download the dataset and place it under current directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02RioHPryvOz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "09de6698-1884-40f3-f4fb-a2212ee2ea96"
      },
      "source": [
        "# Download data\n",
        "!wget -nv -O /content/6864-hw2b/train.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget -nv -O /content/6864-hw2b/train.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "!wget -nv -O /content/6864-hw2b/tst2013.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "!wget -nv -O /content/6864-hw2b/tst2013.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n",
        "!wget -nv -O /content/6864-hw2b/vocab.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en\n",
        "!wget -nv -O /content/6864-hw2b/vocab.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-01 02:45:25 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en [13603614/13603614] -> \"/content/6864-hw2b/train.en\" [1]\n",
            "2020-04-01 02:45:26 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi [18074646/18074646] -> \"/content/6864-hw2b/train.vi\" [1]\n",
            "2020-04-01 02:45:27 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en [132264/132264] -> \"/content/6864-hw2b/tst2013.en\" [1]\n",
            "2020-04-01 02:45:28 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi [183855/183855] -> \"/content/6864-hw2b/tst2013.vi\" [1]\n",
            "2020-04-01 02:45:29 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en [139741/139741] -> \"/content/6864-hw2b/vocab.en\" [1]\n",
            "2020-04-01 02:45:30 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi [46767/46767] -> \"/content/6864-hw2b/vocab.vi\" [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogFESHAf-6MY"
      },
      "source": [
        "Next, we do some simple data preprocessing and show some data statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfkQGqV30hgC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "9e2760ef-4ae8-44fd-d433-0a715047174a"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def read_sentence_file(filename):\n",
        "  sentences_list = []\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      sentences_list.append(line.strip().split())\n",
        "  return sentences_list\n",
        "\n",
        "def read_vocab_file(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return [line.strip() for line in f]\n",
        "\n",
        "\n",
        "src_vocab_set = read_vocab_file(os.path.join(\"/content/6864-hw2b\", \"vocab.vi\"))\n",
        "trg_vocab_set = read_vocab_file(os.path.join(\"/content/6864-hw2b\", \"vocab.en\"))\n",
        "\n",
        "train_src_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
        "                                                           \"train.vi\"))\n",
        "train_trg_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
        "                                                           \"train.en\"))\n",
        "assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n",
        "\n",
        "test_src_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
        "                                                          \"tst2013.vi\"))\n",
        "test_trg_sentences_list = read_sentence_file(os.path.join(\"/content/6864-hw2b\",\n",
        "                                                          \"tst2013.en\"))\n",
        "assert len(test_src_sentences_list) == len(test_trg_sentences_list)\n",
        "\n",
        "\n",
        "MAX_SENT_LENGTH = 48\n",
        "MAX_SENT_LENGTH_PLUS_SOS_EOS = 50\n",
        "max_sent_length_define = 20\n",
        "min_sent_length_define = 10\n",
        "\n",
        "# We only keep sentences that do not exceed 48 words, so that later when we\n",
        "# add <s> and </s> to a sentence it still won't exceed 50 words.\n",
        "def filter_data(src_sentences_list, trg_sentences_list, max_len, min_len):\n",
        "  new_src_sentences_list, new_trg_sentences_list = [], []\n",
        "  for src_sent, trg_sent in zip(src_sentences_list, trg_sentences_list):\n",
        "    if (len(src_sent) <= max_len and len(trg_sent) <= max_len\n",
        "        and len(src_sent) > min_len and len(trg_sent)) > min_len:\n",
        "      new_src_sentences_list.append(src_sent)\n",
        "      new_trg_sentences_list.append(trg_sent)\n",
        "  return new_src_sentences_list, new_trg_sentences_list\n",
        "\n",
        "max_len = max_sent_length_define\n",
        "min_len = min_sent_length_define\n",
        "train_src_sentences_list, train_trg_sentences_list = filter_data(\n",
        "    train_src_sentences_list, train_trg_sentences_list, max_len, min_len)\n",
        "test_src_sentences_list, test_trg_sentences_list = filter_data(\n",
        "    test_src_sentences_list, test_trg_sentences_list, max_len, min_len)\n",
        "\n",
        "# We take 10% of training data as validation set.\n",
        "num_val = int(len(train_src_sentences_list) * 0.1)\n",
        "val_src_sentences_list = train_src_sentences_list[:num_val]\n",
        "val_trg_sentences_list = train_trg_sentences_list[:num_val]\n",
        "train_src_sentences_list = train_src_sentences_list[num_val:]\n",
        "train_trg_sentences_list = train_trg_sentences_list[num_val:]\n",
        "\n",
        "# Show some data stats\n",
        "print(\"Number of training (src, trg) sentence pairs: %d\" %\n",
        "      len(train_src_sentences_list))\n",
        "print(\"Number of validation (src, trg) sentence pairs: %d\" %\n",
        "      len(val_src_sentences_list))\n",
        "print(\"Number of testing (src, trg) sentence pairs: %d\" %\n",
        "      len(test_src_sentences_list))\n",
        "src_vocab_set = ['<pad>'] + src_vocab_set\n",
        "trg_vocab_set = ['<pad>'] + trg_vocab_set\n",
        "print(\"Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n",
        "      len(src_vocab_set))\n",
        "print(\"Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n",
        "      len(trg_vocab_set))\n",
        "\n",
        "length = [len(sent) for sent in train_src_sentences_list]\n",
        "print('Training sentence avg. length: %d ' % np.mean(length))\n",
        "print('Training sentence length at 95-percentile: %d' %\n",
        "      np.percentile(length, 95))\n",
        "print('Training sentence length distribution '\n",
        "      '(x-axis is length range and y-axis is count):\\n')\n",
        "plt.hist(length, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('Example Vietnamese input: ' + str(train_src_sentences_list[0]))\n",
        "print('Its target English output: ' + str(train_trg_sentences_list[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training (src, trg) sentence pairs: 28794\n",
            "Number of validation (src, trg) sentence pairs: 3199\n",
            "Number of testing (src, trg) sentence pairs: 250\n",
            "Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 7710\n",
            "Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 17192\n",
            "Training sentence avg. length: 16 \n",
            "Training sentence length at 95-percentile: 20\n",
            "Training sentence length distribution (x-axis is length range and y-axis is count):\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Example Vietnamese input: ['ZK', ':', 'Đây', 'là', 'Steve', '.', 'Được', 'rồi', 'Steve', ',', 'bây', 'giờ', 'đi', 'theo', 'tôi', 'nhé', '.']\n",
            "Its target English output: ['ZK', ':', 'It', '&apos;s', 'Steve', '.', 'All', 'right', 'Steve', ',', 'now', ',', 'follow', 'me', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2x0lhVm_Yxx"
      },
      "source": [
        "Here we define a class called `MTDataset`. It is built on top of the efficient data loader API provided in PyTorch. See Section 5 for explanation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muwDBzXM5ijT"
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "assert device == \"cuda\"   # use gpu whenever you can!\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "\n",
        "# These IDs are reserved.\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "SOS_INDEX = 2\n",
        "EOS_INDEX = 3\n",
        "\n",
        "\n",
        "class MTDataset(data.Dataset):\n",
        "  def __init__(self, src_sentences, src_vocabs, trg_sentences, trg_vocabs,\n",
        "               sampling=1.):\n",
        "    self.src_sentences = src_sentences[:int(len(src_sentences) * sampling)]\n",
        "    self.trg_sentences = trg_sentences[:int(len(src_sentences) * sampling)]\n",
        "\n",
        "    self.max_src_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "    self.max_trg_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "\n",
        "    self.src_vocabs = src_vocabs\n",
        "    self.trg_vocabs = trg_vocabs\n",
        "\n",
        "    self.src_v2id = {v : i for i, v in enumerate(src_vocabs)}\n",
        "    self.src_id2v = {val : key for key, val in self.src_v2id.items()}\n",
        "    self.trg_v2id = {v : i for i, v in enumerate(trg_vocabs)}\n",
        "    self.trg_id2v = {val : key for key, val in self.trg_v2id.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src_sentences)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    src_sent = self.src_sentences[index]\n",
        "    src_len = len(src_sent) + 2   # add <s> and </s> to each sentence\n",
        "    src_id = []\n",
        "    for w in src_sent:\n",
        "      if w not in self.src_vocabs:\n",
        "        w = '<unk>'\n",
        "      src_id.append(self.src_v2id[w])\n",
        "    src_id = ([SOS_INDEX] + src_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_src_seq_length - src_len))\n",
        "\n",
        "    trg_sent = self.trg_sentences[index]\n",
        "    trg_len = len(trg_sent) + 2\n",
        "    trg_id = []\n",
        "    for w in trg_sent:\n",
        "      if w not in self.trg_vocabs:\n",
        "        w = '<unk>'\n",
        "      trg_id.append(self.trg_v2id[w])\n",
        "    trg_id = ([SOS_INDEX] + trg_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_trg_seq_length - trg_len))\n",
        "\n",
        "    return torch.tensor(src_id), src_len, torch.tensor(trg_id), trg_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb5gQEp7oVdi"
      },
      "source": [
        "## **Section 2: Encoder**\n",
        "\n",
        "Seq2seq consists of an Encoder RNN and a decoder RNN. In a vanilla seq2seq model where there is no attention mechanism between encoder and decoder, the encoder aims to compress the information contained in the entire input sequence into a single vector and pass it to decoder.\n",
        "\n",
        "We start with implementing the encoder, which is just a simple RNN. We use a GRU here, but feel free to try other cell types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnwVGDVkoPt0"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers = 1, bidirection = False, dropout=0.):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "      - `input_size`: an int representing the RNN input size.\n",
        "      - `hidden_size`: an int representing the RNN hidden size.\n",
        "      - `dropout`: a float representing the dropout rate during training. Note\n",
        "          that for 1-layer RNN this has no effect since dropout only applies to\n",
        "          outputs of intermediate layers.\n",
        "    \"\"\"\n",
        "    \n",
        "    super(Encoder, self).__init__()\n",
        "    # Note: for lab writeup question #4, you can directly change `num_layers`\n",
        "    # and `bidirectional` here to enable deep/bidirectional RNNs. However, you\n",
        "    # will also need to modify some parts in the rest of the code accordingly.\n",
        "    \n",
        "    self.bidirection = bidirection\n",
        "    self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True,\n",
        "                      dropout=dropout, bidirectional=self.bidirection)\n",
        "    self.bi_linear = nn.Linear(2*hidden_size, hidden_size)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "    \n",
        "  def forward(self, inputs, lengths):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of source\n",
        "          sentences.\n",
        "      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n",
        "          lengths of `inputs`.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "        (batch_size, max_seq_length, hidden_size).\n",
        "      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n",
        "      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n",
        "      https://pytorch.org/docs/stable/nn.html#gru\n",
        "    \"\"\"\n",
        "    pack_pad = pack_padded_sequence(self.drop(inputs), lengths, batch_first=True, enforce_sorted=False)\n",
        "    ### Your code here!\n",
        "    outputs, finals = self.gru(pack_pad)\n",
        "    outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length = inputs.size(1))\n",
        "    \n",
        "    if self.bidirection:\n",
        "        forward = finals[0:list(finals.size())[0]:2]\n",
        "        backward = finals[1:list(finals.size())[0]:2]\n",
        "        finals = torch.cat([forward, backward], dim=2)\n",
        "        finals = self.bi_linear(finals)\n",
        "        outputs = self.bi_linear(outputs)\n",
        "        \n",
        "    return outputs, finals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oz3Kc4QKyEP"
      },
      "source": [
        "## **Section 3: Decoder**\n",
        "\n",
        "Here you will implement a decoder RNN that uses encoder's last hidden state to initialize its initial hidden state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYT0BlfYUJXj"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  \"\"\"An RNN decoder without attention.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, num_layers = 1, feed_ratio = 0.5, dropout=0.):\n",
        "    \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
        "    \"\"\"\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    ### Your code here!\n",
        "    self.hidden_size = hidden_size\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "    self.input_hidden = nn.Linear(input_size, hidden_size)\n",
        "    self.feed_ratio = feed_ratio\n",
        "    \n",
        "  def forward(self, inputs, encoder_finals, hidden=None, max_len=None):\n",
        "    \"\"\"Unroll the decoder one step at a time.\n",
        "\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of target\n",
        "          sentences (for teacher-forcing during training).\n",
        "      - `encoder_finals`: a 3d-tensor of shape\n",
        "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
        "          encoder hidden states used to initialize the initial decoder hidden\n",
        "          states.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the value to be used to initialize the initial decoder hidden states.\n",
        "          If None, then use `encoder_finals`.\n",
        "      - `max_len`: an int representing the maximum decoding length.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the raw\n",
        "          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n",
        "          We will convert it later in a `Generator` below.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
        "          representing the last decoder hidden state.\n",
        "    \"\"\"\n",
        "\n",
        "    # The maximum number of steps to unroll the RNN.\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    # Initialize decoder hidden state.\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    #outputs = None\n",
        "    ### Your code here!\n",
        "    \n",
        "    outputs = []\n",
        "    for i in range(max_len):\n",
        "        if i == 0:\n",
        "            embed_input = self.input_hidden(F.relu(inputs[:,i,:].unsqueeze(1)))\n",
        "            output, hidden = self.gru(embed_input, hidden)\n",
        "        else:\n",
        "            feed_target = True if random.random() < self.feed_ratio else False\n",
        "            if feed_target:\n",
        "                embed_input = self.input_hidden(F.relu(inputs[:,i,:].unsqueeze(1)))\n",
        "            else:\n",
        "                embed_input = output\n",
        "            \n",
        "            output, hidden = self.gru(embed_input, hidden)\n",
        "            \n",
        "        outputs.append(output)\n",
        "    \n",
        "    outputs = torch.cat(outputs, dim = 1)\n",
        "    \n",
        "    return hidden, outputs\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
        "    state.\"\"\"\n",
        "    ### Your code here!\n",
        "    if encoder_finals != None:\n",
        "        return torch.tanh(encoder_finals)\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH0VdHE2_x1k"
      },
      "source": [
        "Define the high level encoder-decoder class to wrap up sub-models, including encoder, decoder, generator, and src/trg embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNBaAYB_oHxG"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"A standard Encoder-Decoder architecture without attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `encoder`: an `Encoder` object.\n",
        "      - `decoder`: an `Decoder` object.\n",
        "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "          input (source) sentences.\n",
        "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
        "          output (target) sentences.\n",
        "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
        "          the next code cell.\n",
        "    \"\"\"\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    \"\"\"Take in and process masked source and target sequences.\n",
        "\n",
        "    Inputs:\n",
        "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of source sentences of word ids.\n",
        "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of target sentences of word ids.\n",
        "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
        "        sequence length of `src_ids`.\n",
        "\n",
        "    Returns the decoder outputs, see the above cell.\n",
        "    \"\"\"\n",
        "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    del encoder_hiddens   # unused\n",
        "    return self.decode(encoder_finals, trg_ids[:, :-1])\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, encoder_finals, trg_ids, decoder_hidden=None):\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_finals, decoder_hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M06QOTbCALGy"
      },
      "source": [
        "It simply projects the pre-output layer (x in the forward function below) to obtain the output layer, so that the final dimension is the target vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaHdVcF1KPmd"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "  def __init__(self, hidden_size, vocab_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf8Oc9a_ocC_"
      },
      "source": [
        "## **Section 4: Attention-Based Decoder**\n",
        "\n",
        "Now it's time to add some attention to the decoder. You can implement any attention mechanism you want.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZq2NImAoY1C"
      },
      "source": [
        "class BahAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.q_weight = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.k_weight = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.va = nn.Linear(hidden_size, 1, bias=False)\n",
        "        self.att_weight = None\n",
        "        \n",
        "    def forward(self, q, k, v, mask):\n",
        "        #q = q.unsqueeze(1)\n",
        "        #q_linear = nn.Linear(q.size(2), self.hidden_size).cuda()\n",
        "        #k_linear = nn.Linear(k.size(2), self.hidden_size).cuda()\n",
        "        #print(list(q_p.size()))\n",
        "        #k_p = self.k_weight(k)\n",
        "        #print(list(k.size()))\n",
        "        combine = torch.tanh(self.q_weight(q) + self.k_weight(k))\n",
        "        energy = self.va(combine).squeeze(2).unsqueeze(1)\n",
        "        energy.data.masked_fill_(mask == False, -float('inf'))\n",
        "        att_weight = F.softmax(energy, dim=-1)\n",
        "        self.att_weight = att_weight\n",
        "        context = att_weight.bmm(v)\n",
        "        return context\n",
        "\n",
        "'''\n",
        "AttentionDecoder\n",
        "'''\n",
        "\n",
        "class AttentionDecoder(nn.Module):\n",
        "  \"\"\"An attention-based RNN decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, attention, num_layers, feed_ratio = 0.5, dropout=0.):\n",
        "    \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
        "        - `attention`: this is your self-defined Attention object. You can\n",
        "            either define an individual class for your Attention and pass it\n",
        "            here or leave `attention` as None and just implement everything\n",
        "            here.\n",
        "    \"\"\"\n",
        "    super(AttentionDecoder, self).__init__()\n",
        "\n",
        "    ### Your code here!\n",
        "    self.hidden_size = hidden_size\n",
        "    self.input_size = input_size\n",
        "    self.dropout = dropout\n",
        "    self.feed_ratio = feed_ratio\n",
        "\n",
        "    self.attention = attention\n",
        "    self.input_hidden = nn.Linear(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size*2, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "    self.drop_layer = nn.Dropout(dropout)\n",
        "    self.output1 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.output2 = nn.Linear(hidden_size*3, hidden_size)\n",
        "\n",
        "    \n",
        "  def forward(self, inputs, encoder_hiddens, encoder_finals,  src_mask,\n",
        "              hidden=None, trg_mask = None, max_len=None):\n",
        "    \"\"\"Unroll the decoder one step at a time.\n",
        "    \n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of target\n",
        "          sentences (for teacher-forcing during training).\n",
        "      - `encoder_hiddens`: a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the encoder\n",
        "          outputs for each decoding step to attend to. \n",
        "      - `encoder_finals`: a 3d-tensor of shape\n",
        "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
        "          encoder hidden states used to initialize the initial decoder hidden\n",
        "          states.\n",
        "      - `src_mask`: a 3d-tensor of shape (batch_size, 1, max_seq_length)\n",
        "          representing the mask for source sentences.\n",
        "      - `trg_mask`: a 3d-tensor of shape (batch_size, 1, max_seq_length)\n",
        "          representing the mask for target sentences.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the value to be used to initialize the initial decoder hidden states.\n",
        "          If None, then use `encoder_finals`.\n",
        "      - `max_len`: an int representing the maximum decoding length.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: (same as in Decoder) a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the raw\n",
        "          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
        "          representing the last decoder hidden state.\n",
        "    \"\"\"\n",
        "\n",
        "    # The maximum number of steps to unroll the RNN.\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    if hidden is None:\n",
        "      #print('encoder final')\n",
        "      #print(encoder_finals.size())\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    #outputs = None\n",
        "    ### Your code here!\n",
        "    \n",
        "    #print('input')\n",
        "    #print(inputs.size())\n",
        "    #print(self.input_size)\n",
        "    #print('max_len: ' + str(max_len))\n",
        "\n",
        "    outputs = []\n",
        "    for i in range(max_len):\n",
        "        #print(hidden[-1].size())\n",
        "        #print(hidden[-1].unsqueeze(1).size())\n",
        "        context = self.attention(hidden[-1].unsqueeze(1), encoder_hiddens, encoder_hiddens, src_mask)\n",
        "        if i == 0:\n",
        "            embed_input = self.input_hidden(inputs[:,i,:].unsqueeze(1))\n",
        "            lstm_input = torch.cat([context, self.drop_layer(embed_input)], dim = -1)\n",
        "            #print('hidden size')\n",
        "            #print(hidden[0].size())\n",
        "            output, (hidden, cell) = self.lstm(lstm_input, (hidden, hidden))\n",
        "            \n",
        "        else:\n",
        "            feed_target = True if random.random() < self.feed_ratio else False\n",
        "            if feed_target:\n",
        "                embed_input = self.input_hidden(inputs[:,i,:].unsqueeze(1))\n",
        "            else:\n",
        "                embed_input = output\n",
        "            \n",
        "            lstm_input = torch.cat([context, self.drop_layer(embed_input)], dim = -1)\n",
        "            #print('hidden size')\n",
        "            #print(hidden.size())\n",
        "            output, (hidden, cell) = self.lstm(lstm_input, (hidden, hidden))\n",
        "            \n",
        "        \n",
        "        result1 = self.output1(output + context)\n",
        "        #result2 = self.output2(torch.cat([output, context, embed_input]), dim = -1)\n",
        "        outputs.append(result1)\n",
        "        #outputs.append(result2)\n",
        "    \n",
        "    outputs = torch.cat(outputs, dim = 1)\n",
        "    \n",
        "    return hidden, outputs\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
        "    state.\"\"\"\n",
        "    #decoder_init_hiddens = None\n",
        "    ### Your code here!\n",
        "    \n",
        "    if encoder_finals != None:\n",
        "        return torch.tanh(encoder_finals)\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTUXxJWPPQ9W"
      },
      "source": [
        "Similarly, we use a `EncoderAttentionDecoder` class to wrap up all encoder, decoder, src/trg embeddings, and generator. You can take the `EncoderDecoder` class as a reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mghIa6XzubZL"
      },
      "source": [
        "class EncoderAttentionDecoder(nn.Module):\n",
        "  \"\"\"A Encoder-Decoder architecture with attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed , trg_embed, generator):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `encoder`: an `Encoder` object.\n",
        "      - `decoder`: an `AttentionDecoder` object.\n",
        "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "          input (source) sentences.\n",
        "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
        "          output (target) sentences.\n",
        "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
        "          the next code cell.\n",
        "    \"\"\"\n",
        "    super(EncoderAttentionDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    \"\"\"Take in and process masked source and tar get sequences.\n",
        "\n",
        "    Inputs:\n",
        "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of source sentences of word ids.\n",
        "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of target sentences of word ids.\n",
        "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
        "        sequence length of `src_ids`.\n",
        "\n",
        "    Returns the decoder outputs, see the above cell.\n",
        "    \"\"\"\n",
        "    ### Your code here!\n",
        "    # You can refer to `EncoderDecoder` and extend from it.\n",
        "    src_mask = (src_ids != 0).unsqueeze(1)\n",
        "    #print(src_ids.size())\n",
        "    #print(src_mask.size())\n",
        "    encoder_output, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    #print('output')\n",
        "    #print(encoder_output.size())\n",
        "    return self.decode(encoder_finals, encoder_output, trg_ids[:, :-1], src_mask)\n",
        "    \n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, encoder_finals, encoder_hiddens, trg_ids, src_mask, decoder_hidden=None):\n",
        "    #print(trg_ids.size())\n",
        "    #print(src_mask.size())\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_hiddens, encoder_finals, src_mask, decoder_hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIpNlKtK8l_"
      },
      "source": [
        "## **Section 5: Training and Testing**\n",
        "\n",
        "We provide training and testing scripts here. You might need to adapt them to fit your model implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I38IFq48BKa5"
      },
      "source": [
        "Apply the dataloader to the MT dataset. Dataloader provides a convenient way to iterate through the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJrXO7nCjzBP"
      },
      "source": [
        "batch_size = 128\n",
        "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
        "hidden_size = 256  # RNN hidden size.\n",
        "dropout = 0.2\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "feed_ratio = 0.7\n",
        "learning_rate = 9e-4\n",
        "clipping_value = 1 \n",
        "num_epochs = 12\n",
        "\n",
        "train_set = MTDataset(train_src_sentences_list, src_vocab_set,\n",
        "                      train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "train_data_loader = data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                    num_workers=8, shuffle=True)\n",
        "\n",
        "val_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                    val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "val_data_loader = data.DataLoader(val_set, batch_size=batch_size, num_workers=8, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWaiu7wNBX7x"
      },
      "source": [
        "The main functions for training, here we use perplexity to evaluate the performance of the model. Although we provide the training scripts here, we strongly encoureage you to go through and understand the procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGa-L1qp13q"
      },
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class SimpleLossCompute:\n",
        "  \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "  def __init__(self, generator, criterion, opt=None, c_value = None, model = None):\n",
        "    self.generator = generator\n",
        "    self.criterion = criterion\n",
        "    self.opt = opt\n",
        "    self.clipping_value = c_value\n",
        "    self.model = model\n",
        "\n",
        "  def __call__(self, x, y, norm):\n",
        "    x = self.generator(x)\n",
        "    loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                          y.contiguous().view(-1))\n",
        "    loss = loss / norm\n",
        "\n",
        "    if self.opt is not None:  # training mode\n",
        "      loss.backward()    \n",
        "      ########################## clip\n",
        "      torch.nn.utils.clip_grad_norm(self.model.parameters(), self.clipping_value)\n",
        "      ##########################\n",
        "      self.opt.step()\n",
        "      self.opt.zero_grad()\n",
        "\n",
        "    return loss.data.item() * norm\n",
        "\n",
        "\n",
        "def run_epoch(data_loader, model, loss_compute, print_every):\n",
        "  \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "  total_tokens = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n",
        "    # We define some notations here to help you understand the loaded tensor\n",
        "    # shapes:\n",
        "    #   `B`: batch size\n",
        "    #   `T`: max sequence length of source sentences\n",
        "    #   `L`: max sequence length of target sentences; due to our preprocessing\n",
        "    #        in the beginning, `L` == `T` == 50\n",
        "    # An example of `src_ids_BxT` (when B = 2):\n",
        "    #   [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n",
        "    #    [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n",
        "    # The corresponding `src_lengths_B` would be [47, 49].\n",
        "    # Note that SOS_INDEX == 2, EOS_INDEX == 3, and PAD_INDEX = 0.\n",
        "\n",
        "    src_ids_BxT = src_ids_BxT.to(device)\n",
        "    src_lengths_B = src_lengths_B.to(device)\n",
        "    trg_ids_BxL = trg_ids_BxL.to(device)\n",
        "    del trg_lengths_B   # unused\n",
        "\n",
        "    _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
        "\n",
        "    loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:],\n",
        "                        norm=src_ids_BxT.size(0))\n",
        "    total_loss += loss\n",
        "    total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
        "\n",
        "    if model.training and i % print_every == 0:\n",
        "      print(\"Epoch Step: %d Loss: %f\" % (i, loss / src_ids_BxT.size(0)))\n",
        "\n",
        "  return math.exp(total_loss / float(total_tokens))\n",
        "\n",
        "\n",
        "def train(model, num_epochs, learning_rate, print_every, clipping_value):\n",
        "  # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when\n",
        "  # computing the loss.\n",
        "  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Keep track of dev ppl for each epoch.\n",
        "  dev_ppls = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch\", epoch)\n",
        "\n",
        "    model.train()\n",
        "    train_ppl = run_epoch(data_loader=train_data_loader, model=model,\n",
        "                          loss_compute=SimpleLossCompute(model.generator,\n",
        "                                                         criterion, optim, clipping_value, model),\n",
        "                          print_every=print_every)\n",
        "        \n",
        "    model.eval()\n",
        "    with torch.no_grad():      \n",
        "      dev_ppl = run_epoch(data_loader=val_data_loader, model=model,\n",
        "                          loss_compute=SimpleLossCompute(model.generator,\n",
        "                                                         criterion, None, None),\n",
        "                          print_every=print_every)\n",
        "      print(\"Validation perplexity: %f\" % dev_ppl)\n",
        "      dev_ppls.append(dev_ppl)\n",
        "        \n",
        "  return dev_ppls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A8VvkcICT60"
      },
      "source": [
        "The main function to perform training. First let's train the vanilla seq2seq model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ0t1hXAIHtO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04b188dd-2036-42a5-b941-d560a6403e12"
      },
      "source": [
        "pure_seq2seq = EncoderDecoder(\n",
        "  encoder=Encoder(embed_size, hidden_size, num_layers, bidirection, dropout),\n",
        "  decoder=Decoder(embed_size, hidden_size, num_layers, feed_ratio, dropout),\n",
        "  src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
        "  trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "  generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "# Start training. The returned `dev_ppls` is a list of dev perplexity for each\n",
        "# epoch.\n",
        "pure_dev_ppls = train(pure_seq2seq, num_epochs, learning_rate, 100, clipping_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 0 Loss: 141.728058\n",
            "Epoch Step: 100 Loss: 90.291069\n",
            "Epoch Step: 200 Loss: 84.712387\n",
            "Validation perplexity: 282.241928\n",
            "Epoch 1\n",
            "Epoch Step: 0 Loss: 87.433334\n",
            "Epoch Step: 100 Loss: 81.076218\n",
            "Epoch Step: 200 Loss: 75.921570\n",
            "Validation perplexity: 186.802324\n",
            "Epoch 2\n",
            "Epoch Step: 0 Loss: 76.087349\n",
            "Epoch Step: 100 Loss: 75.104538\n",
            "Epoch Step: 200 Loss: 74.405930\n",
            "Validation perplexity: 118.042619\n",
            "Epoch 3\n",
            "Epoch Step: 0 Loss: 70.049950\n",
            "Epoch Step: 100 Loss: 67.604645\n",
            "Epoch Step: 200 Loss: 68.130005\n",
            "Validation perplexity: 91.846290\n",
            "Epoch 4\n",
            "Epoch Step: 0 Loss: 66.978271\n",
            "Epoch Step: 100 Loss: 64.168861\n",
            "Epoch Step: 200 Loss: 65.635277\n",
            "Validation perplexity: 81.000684\n",
            "Epoch 5\n",
            "Epoch Step: 0 Loss: 62.689007\n",
            "Epoch Step: 100 Loss: 60.329247\n",
            "Epoch Step: 200 Loss: 61.952374\n",
            "Validation perplexity: 74.681580\n",
            "Epoch 6\n",
            "Epoch Step: 0 Loss: 59.026642\n",
            "Epoch Step: 100 Loss: 58.884418\n",
            "Epoch Step: 200 Loss: 59.074776\n",
            "Validation perplexity: 71.951722\n",
            "Epoch 7\n",
            "Epoch Step: 0 Loss: 56.086044\n",
            "Epoch Step: 100 Loss: 60.329174\n",
            "Epoch Step: 200 Loss: 55.705734\n",
            "Validation perplexity: 64.534274\n",
            "Epoch 8\n",
            "Epoch Step: 0 Loss: 55.897297\n",
            "Epoch Step: 100 Loss: 52.662956\n",
            "Epoch Step: 200 Loss: 55.444057\n",
            "Validation perplexity: 65.668637\n",
            "Epoch 9\n",
            "Epoch Step: 0 Loss: 54.860413\n",
            "Epoch Step: 100 Loss: 53.219982\n",
            "Epoch Step: 200 Loss: 51.976231\n",
            "Validation perplexity: 63.792683\n",
            "Epoch 10\n",
            "Epoch Step: 0 Loss: 50.011864\n",
            "Epoch Step: 100 Loss: 52.534897\n",
            "Epoch Step: 200 Loss: 53.057415\n",
            "Validation perplexity: 62.151501\n",
            "Epoch 11\n",
            "Epoch Step: 0 Loss: 48.739555\n",
            "Epoch Step: 100 Loss: 44.575775\n",
            "Epoch Step: 200 Loss: 50.330688\n",
            "Validation perplexity: 62.667145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRsfDg0wCa7U"
      },
      "source": [
        "Plot the perplexity graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTApnlT53YvT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "883e8392-16d5-4f9b-e586-e8abcab80698"
      },
      "source": [
        "def plot_perplexity(perplexities):\n",
        "  \"\"\"plot perplexities\"\"\"\n",
        "  plt.title(\"Perplexity per Epoch\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Perplexity\")\n",
        "  plt.plot(perplexities)\n",
        "\n",
        "plot_perplexity(pure_dev_ppls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjhKXDyvIk4l"
      },
      "source": [
        "Now, let's train the seq2seq model with attention."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onQxDU-aGa0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b1b7032-190c-4774-aee5-7fcccfe614bc"
      },
      "source": [
        "attention = BahAttention(hidden_size)\n",
        "attn_seq2seq = EncoderAttentionDecoder(\n",
        "  encoder=Encoder(embed_size, hidden_size, num_layers, bidirection, dropout),\n",
        "  decoder=AttentionDecoder(embed_size, hidden_size, attention, num_layers, feed_ratio, dropout),\n",
        "  src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
        "  trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "  generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "attn_dev_ppls = train(attn_seq2seq, num_epochs, learning_rate, 100, clipping_value)\n",
        "\n",
        "plot_perplexity(attn_dev_ppls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 0 Loss: 144.999466\n",
            "Epoch Step: 100 Loss: 80.566689\n",
            "Epoch Step: 200 Loss: 71.372269\n",
            "Validation perplexity: 94.265278\n",
            "Epoch 1\n",
            "Epoch Step: 0 Loss: 66.691887\n",
            "Epoch Step: 100 Loss: 61.506195\n",
            "Epoch Step: 200 Loss: 59.452625\n",
            "Validation perplexity: 57.283866\n",
            "Epoch 2\n",
            "Epoch Step: 0 Loss: 57.734486\n",
            "Epoch Step: 100 Loss: 49.604027\n",
            "Epoch Step: 200 Loss: 53.692616\n",
            "Validation perplexity: 45.135871\n",
            "Epoch 3\n",
            "Epoch Step: 0 Loss: 52.629532\n",
            "Epoch Step: 100 Loss: 49.603035\n",
            "Epoch Step: 200 Loss: 47.753555\n",
            "Validation perplexity: 38.771326\n",
            "Epoch 4\n",
            "Epoch Step: 0 Loss: 49.940273\n",
            "Epoch Step: 100 Loss: 44.750519\n",
            "Epoch Step: 200 Loss: 47.932846\n",
            "Validation perplexity: 39.187900\n",
            "Epoch 5\n",
            "Epoch Step: 0 Loss: 42.706295\n",
            "Epoch Step: 100 Loss: 39.681461\n",
            "Epoch Step: 200 Loss: 43.184708\n",
            "Validation perplexity: 38.179853\n",
            "Epoch 6\n",
            "Epoch Step: 0 Loss: 34.690266\n",
            "Epoch Step: 100 Loss: 40.026253\n",
            "Epoch Step: 200 Loss: 40.850811\n",
            "Validation perplexity: 35.485375\n",
            "Epoch 7\n",
            "Epoch Step: 0 Loss: 38.922245\n",
            "Epoch Step: 100 Loss: 39.854961\n",
            "Epoch Step: 200 Loss: 35.237530\n",
            "Validation perplexity: 37.501011\n",
            "Epoch 8\n",
            "Epoch Step: 0 Loss: 40.562759\n",
            "Epoch Step: 100 Loss: 34.768909\n",
            "Epoch Step: 200 Loss: 38.289902\n",
            "Validation perplexity: 37.756003\n",
            "Epoch 9\n",
            "Epoch Step: 0 Loss: 31.795078\n",
            "Epoch Step: 100 Loss: 31.226946\n",
            "Epoch Step: 200 Loss: 36.755009\n",
            "Validation perplexity: 37.571274\n",
            "Epoch 10\n",
            "Epoch Step: 0 Loss: 31.712284\n",
            "Epoch Step: 100 Loss: 33.275276\n",
            "Epoch Step: 200 Loss: 35.276966\n",
            "Validation perplexity: 38.670194\n",
            "Epoch 11\n",
            "Epoch Step: 0 Loss: 29.824112\n",
            "Epoch Step: 100 Loss: 32.404686\n",
            "Epoch Step: 200 Loss: 31.525492\n",
            "Validation perplexity: 40.999578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njIJfRCRmFPwiIjGj4BcRiZn/D+R2URe4MjH7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMpL-_MwJOws"
      },
      "source": [
        "This is the function used to decode the model output. For simplicity, we use greedy search here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1HTqYwy6-yL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d195a6ca-0b9d-4e77-83e9-25b159934744"
      },
      "source": [
        "plt.title(\"Perplexity per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Perplexity\")\n",
        "plt.plot(pure_dev_ppls, label='pure model')\n",
        "plt.plot(attn_dev_ppls, label='attn model')\n",
        "plt.legend(loc = 'upper right')\n",
        "\n",
        "def greedy_decode(model, src_ids, src_lengths, max_len, pad_index = 0):\n",
        "  \"\"\"Greedily decode a sentence for EncoderDecoder.\"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_hiddens, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "  attn_scores = []\n",
        "\n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "        if model == pure_seq2seq:\n",
        "            hidden, outputs = model.decode(encoder_finals, prev_y, hidden)\n",
        "        if model == attn_seq2seq:\n",
        "            src_mask = (src_ids != pad_index).unsqueeze(1)\n",
        "            hidden, outputs = model.decode(encoder_finals, encoder_hiddens, prev_y, src_mask, hidden)\n",
        "            attn_score = model.decoder.attention.att_weight.cpu().numpy()\n",
        "            attn_scores.append(attn_score)\n",
        "            \n",
        "        prob = model.generator(outputs[:, -1])\n",
        "\n",
        "    _, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "  attn_scores = np.array(attn_scores)\n",
        "\n",
        "  # Cut off everything starting from </s>.\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "\n",
        "  #print(np.array(attn_scores))\n",
        "  return output, attn_scores.reshape(max_len, -1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab):\n",
        "  return [vocab[i] for i in x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTICFgjHGmID/D58Noi8clCufAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_5go3VxJZKh"
      },
      "source": [
        "Print the top 3 examples from the data loader by applying the greedy decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3m4optFrb3"
      },
      "source": [
        "def print_examples(model, data_loader, n=5,\n",
        "                   max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS, \n",
        "                   src_vocab_set=src_vocab_set, trg_vocab_set=trg_vocab_set):\n",
        "  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds = []\n",
        "  weights = []\n",
        "\n",
        "  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
        "    pred, attn_scores = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                           max_len=max_len)\n",
        "    \n",
        "    #preds.append(result)\n",
        "    #weights.append(attn_scores)\n",
        "\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    src_w = lookup_words(src_ids, src_vocab_set)\n",
        "    #trg_w = lookup_words(trg_ids, trg_vocab_set)\n",
        "    pred_w = lookup_words(pred, trg_vocab_set)\n",
        "\n",
        "    print(\"Example #%d\" % (i + 1))\n",
        "    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
        "    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
        "    print(\"Pred: \", \" \".join(lookup_words(pred, vocab=trg_vocab_set)))\n",
        "    #print()\n",
        "\n",
        "    if i == n - 1:\n",
        "      break\n",
        "    \n",
        "  return attn_scores, src_w, pred_w\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Hi4X0GJouK"
      },
      "source": [
        "Here we use the validation dataset to print examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27thJIfreCgB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91c9cda3-48ed-4627-acf5-ac130e256771"
      },
      "source": [
        "example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                        val_trg_sentences_list, trg_vocab_set)\n",
        "example_data_loader = data.DataLoader(val_set, batch_size=1, num_workers=1,\n",
        "                                      shuffle=False)\n",
        "\n",
        "attn_score, src_w, pred_w = print_examples(attn_seq2seq, example_data_loader, 13, max_sent_length_define)\n",
        "\n",
        "def attnmap(src, pred, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    att_map = ax.pcolor(scores, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels(pred, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(att_map)\n",
        "    plt.show()\n",
        "\n",
        "attnmap(src_w, pred_w, attn_score[:len(src_w), :len(pred_w)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example #1\n",
            "Src :  Cả hai đều là một nhánh của cùng một lĩnh vực trong ngành khoa học khí quyển .\n",
            "Trg :  They are both two branches of the same field of atmospheric science .\n",
            "Pred:  The both is the same of the final challenge in the science science .\n",
            "Example #2\n",
            "Src :  Nghiên cứu được viết bởi <unk> nhà khoa học từ 40 quốc gia khác nhau .\n",
            "Trg :  That report was written by <unk> scientists from 40 countries .\n",
            "Pred:  So studies studies writing by biologists from <unk> countries .\n",
            "Example #3\n",
            "Src :  Mỗi năm , hơn 15,000 nhà khoa học đến San Francisco để tham dự hội nghị này .\n",
            "Trg :  Over 15,000 scientists go to San Francisco every year for that .\n",
            "Pred:  Every year , 23 trillion dollars came to San bookstore .\n",
            "Example #4\n",
            "Src :  Đó là một lượng khí thải khổng lồ , bằng tổng trọng lượng của <unk> .\n",
            "Trg :  It &apos;s a huge amount of stuff . It &apos;s equal to the weight of methane .\n",
            "Pred:  It &apos;s a huge volume of Spain , by the <unk> of the <unk> .\n",
            "Example #5\n",
            "Src :  Chính vì lượng khí thải rất lớn , nó có ý nghĩa quan trọng với hệ thống khí quyển .\n",
            "Trg :  And because it &apos;s so much stuff , it &apos;s really important for the atmospheric system .\n",
            "Pred:  It &apos;s because the vast vast vast , it &apos;s important to the <unk> system .\n",
            "Example #6\n",
            "Src :  Chúng tôi chạy những mô hình khổng lồ trên siêu máy tính ; đây là công việc của tôi .\n",
            "Trg :  We run enormous models on <unk> ; this is what I happen to do .\n",
            "Pred:  We run these satellite expressions on this computers ; this is my job job .\n",
            "Example #7\n",
            "Src :  Chúng tôi cần làm hàng tá phép tính như thế để hiểu được những gì đang xảy ra .\n",
            "Trg :  And we perform dozens of <unk> in order to understand what &apos;s happening .\n",
            "Pred:  We need to make a dozen level to get lengths to understand what &apos;s going to be happening .\n",
            "Example #8\n",
            "Src :  Chúng tôi còn bay khắp thế giới để tìm phân tử này .\n",
            "Trg :  We also fly all over the world looking for this thing .\n",
            "Pred:  We can still go over the world to find this .\n",
            "Example #9\n",
            "Src :  Gần đây tôi tham gia một cuộc khảo sát thực địa ở Malaysia . Còn nhiều chuyến khác nữa .\n",
            "Trg :  I recently joined a field campaign in Malaysia . There are others .\n",
            "Pred:  Recently recently I &apos;m in a real <unk> crisis . There &apos;s many many other .\n",
            "Example #10\n",
            "Src :  Đây chính là cái tháp giữa rừng sâu , nhìn từ trên cao .\n",
            "Trg :  This is the tower in the middle of the rainforest , from above .\n",
            "Pred:  This is the <unk> between the mirror , at the top .\n",
            "Example #11\n",
            "Src :  Có giai đoạn chúng tôi còn mang cả máy bay theo .\n",
            "Trg :  And on part of that field campaign we even brought an aircraft with us .\n",
            "Pred:  There &apos;s the canopy we brought them up the plane flying .\n",
            "Example #12\n",
            "Src :  Rất có thể bạn đã ở trên một chiếc tương tự khi đến đây hôm nay .\n",
            "Trg :  So maybe you took a similar aircraft to get here today .\n",
            "Pred:  It might be already on a same thing when you can come here today .\n",
            "Example #13\n",
            "Src :  Chúng tôi phải bay với độ nghiêng đặc biệt để thực hiện các phép đo .\n",
            "Trg :  We have to fly at a special <unk> in order to make the measurements .\n",
            "Pred:  We had to fly with a very specific level to do it .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEUCAYAAAAoQI39AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5pTV5PqJtX4"
      },
      "source": [
        "Compute the BLEU score. BLEU score is a standard measure to evaluate the translation results. For further details, you can refer to [this](https://en.wikipedia.org/wiki/BLEU) link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XGQYwHRPyne",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "05238203-4565-4404-c2a7-b759cdd1ad58"
      },
      "source": [
        "import sacrebleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def compute_BLEU(model, data_loader):\n",
        "  bleu_score = []\n",
        "\n",
        "  model.eval()\n",
        "  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n",
        "    result, attn_score = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                           max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    pred = \" \".join(lookup_words(result, vocab=trg_vocab_set))\n",
        "    targ = \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set))\n",
        "\n",
        "    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n",
        "\n",
        "  return bleu_score\n",
        "\n",
        "\n",
        "test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n",
        "                     test_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n",
        "                                   shuffle=False)\n",
        "\n",
        "print('BLEU score: %f' % (np.mean(compute_BLEU(pure_seq2seq,\n",
        "                                               test_data_loader))))\n",
        "print('BLEU score: %f' % (np.mean(compute_BLEU(attn_seq2seq,\n",
        "                                               test_data_loader))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [00:12<00:00, 19.76it/s]\n",
            "  0%|          | 0/250 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU score: 4.326025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [00:18<00:00, 13.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU score: 10.174215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbOgwJw_CkCW"
      },
      "source": [
        "## **Part 3: Lab writeup**\n",
        "\n",
        "Your lab report should discuss any implementation details that were important to filling out the code above. Then, use the code to set up experiments that answer the following questions:\n",
        "\n",
        "1. In this lab we use greedy search for decoding, that is, always taking the most probable word at current timestep as prediction. Describe an alternative decoding method that might work better than greedy search. You don't have to implement it.\n",
        "\n",
        "2. Pick some samples from dev or test set and visualize their attention maps. Discuss your findings. Hint: compute the attention scores on the input words for each timestep during decoding.\n",
        "\n",
        "3. Compare the performance of seq2seq with and without attention on sentences of different lengths. You can set some length intervals (e.g., 1-10, 11-20, 21-30, 31-40, 41-50) and compare the two models' performance within each length interval. Discuss your findings.\n",
        "\n",
        "4. Try to improve your BLEU score. For example, try stacking more RNN layers, switching cell types, or applying bi-direction to encoder. Describe what you try, even if they don't show improvement. Hints:\n",
        "  * TA's preliminary implemtation of seq2seq with attention model achieves around 16. You don't have to surpass it (although it's pretty simple to do so)--this number is just to give you some sense of what a baseline should get.\n",
        "  * Training on the entire training set takes some time. So tune your hyperparameters on a smaller training set (you can do so by changing `sampling` when creating the data loader)."
      ]
    }
  ]
}
